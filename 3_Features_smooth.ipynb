{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spark"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import init_spark\n",
        "import pyspark.sql.functions as sf\n",
        "from pyspark.sql.window import Window as sw\n",
        "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
        "spark = init_spark({\"appName\": 'smooth_features'})"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "plt.style.use(\"bmh\")\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train = spark.table('alfa.andrey_auto_train')\n",
        "test = spark.table('alfa.andrey_auto_test')"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "N_TRAIN = train.count()\n",
        "N_TEST = test.count()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smooth statistics"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA_PERC = 0.1\n",
        "MAX_K = 25"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_statistic(stat_set, apply_set, encoding_list, global_y):\n",
        "    new_feature_name = 'encod_via_' + '_'.join(encoding_list)\n",
        "    stat_set = stat_set.select(['app_id', 'target'] + encoding_list)\n",
        "    apply_set = apply_set.select(['app_id'] + encoding_list)\n",
        "    means = stat_set.groupBy(encoding_list).agg(sf.mean('target').alias(new_feature_name))\n",
        "    apply_set = apply_set.join(means, on=encoding_list, how='left')\n",
        "    apply_set = apply_set.withColumn(new_feature_name,\n",
        "                        sf.lit(1 - ALPHA_PERC) * sf.col(new_feature_name) + sf.lit(global_y * ALPHA_PERC))\n",
        "    apply_set = apply_set.fillna(global_y)\n",
        "    return apply_set"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "target_for_smooth_train = spark.table('alfa.andrey_auto_target_train')\n",
        "target_for_smooth_train = target_for_smooth_train.withColumnRenamed('flag', 'target')\n",
        "train_for_smooth = train.join(target_for_smooth_train, how='inner', on=['app_id'])\n",
        "\n",
        "target_for_smooth_test = spark.table('alfa.andrey_auto_target_test')\n",
        "test_for_smooth = test.join(target_for_smooth_test, how='inner', on=['app_id'])\n",
        "\n",
        "app_id_groups = train_for_smooth.select(['app_id', 'target']).dropDuplicates()\n",
        "app_id_groups = app_id_groups.withColumn('new_column', sf.lit(\"ABC\"))\n",
        "app_id_groups = app_id_groups.withColumn('k', sf.row_number().\\\n",
        "                    over(sw().partitionBy('new_column').orderBy(['target', 'app_id'])))\n",
        "app_id_groups = app_id_groups.drop('new_column')\n",
        "app_id_groups = app_id_groups.withColumn('k', sf.expr(\"mod(k, \" + str(MAX_K) + \")\"))\n",
        "app_id_groups = app_id_groups.select(['app_id', 'k'])"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_GLOBAL_MEAN = train_for_smooth.select(sf.mean('target')).take(1)[0][0]\n",
        "table_for_batches = train_for_smooth.select(['app_id', 'target'])\n",
        "table_for_batches = table_for_batches.join(app_id_groups, how='left', on=['app_id'])\n",
        "batches_mean_target = {}\n",
        "for current_k in range(MAX_K):\n",
        "    batches_mean_target[current_k] =\\\n",
        "        table_for_batches.filter(sf.col('k') != current_k).select(sf.mean('target')).take(1)[0][0]"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "possible_columns = ['product', 'operation_kind', 'card_type', 'operation_type', 'ecommerce_flag', 'income_flag',\n",
        "                    'mcc', 'city', 'mcc_category', 'day_of_week', 'hour', 'weekofyear']\n",
        "all_possible_for_smooth = [[x] for x in possible_columns] + [list(x) for x in list(combinations(possible_columns, 2))]"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_possible_for_smooth = [['product', 'card_type'], ['card_type', 'hour_diff'], ['card_type', 'hour']]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_smooth_table = train.select(['app_id']).dropDuplicates()\n",
        "test_smooth_table = test.select(['app_id']).dropDuplicates()\n",
        "\n",
        "for encoding_list in tqdm(all_possible_for_smooth):\n",
        "    current_smooth = train_for_smooth.select(['app_id', 'target'] + encoding_list)\n",
        "    current_smooth = current_smooth.join(app_id_groups, how='left', on=['app_id'])\n",
        "    current_smooth = current_smooth.withColumn('n_k', sf.count('app_id').over(sw().partitionBy('k')))\n",
        "    current_smooth = current_smooth.withColumn('n_m_k', sf.lit(N_TRAIN) - sf.col('n_k'))\n",
        "    \n",
        "    current_smooth_test = test_for_smooth.select(['app_id'] + encoding_list)\n",
        "    current_smooth_test = current_smooth_test.withColumn('n_m_k', sf.lit(N_TRAIN))\n",
        "\n",
        "    averages = []\n",
        "    new_feature_name = 'encod_via_' + '_'.join(encoding_list)\n",
        "    for c_k in range(MAX_K):\n",
        "        smooth_k = smooth_statistic(current_smooth.filter(sf.col('k') != c_k),\n",
        "                        current_smooth.filter(sf.col('k') == c_k), encoding_list, batches_mean_target[c_k])\n",
        "        averages.append(smooth_k)\n",
        "    \n",
        "    smooth_cv_table = averages[0]\n",
        "    for i in range(1, MAX_K):\n",
        "        smooth_cv_table = smooth_cv_table.union(averages[i])\n",
        "    smooth_test_table = smooth_statistic(current_smooth, current_smooth_test, encoding_list, TRAIN_GLOBAL_MEAN)\n",
        "\n",
        "    if new_feature_name in ['encod_via_card_type_hour']:\n",
        "        smooth_cv_table = smooth_cv_table.groupBy(['app_id']).agg(\n",
        "                                    sf.mean(new_feature_name).alias(new_feature_name + '_mean'))\n",
        "        smooth_test_table = smooth_test_table.groupBy(['app_id']).agg(\n",
        "                                    sf.mean(new_feature_name).alias(new_feature_name + '_mean'))\n",
        "    if new_feature_name in ['encod_via_product_card_type', 'encod_via_card_type_hour_diff']:\n",
        "        smooth_cv_table = smooth_cv_table.groupBy(['app_id']).agg(\n",
        "                                    sf.max(new_feature_name).alias(new_feature_name + '_max'))\n",
        "        smooth_test_table = smooth_test_table.groupBy(['app_id']).agg(\n",
        "                                    sf.max(new_feature_name).alias(new_feature_name + '_max'))\n",
        "\n",
        "    train_smooth_table = train_smooth_table.join(smooth_cv_table, on=['app_id'], how='left')\n",
        "    test_smooth_table = test_smooth_table.join(smooth_test_table, on=['app_id'], how='left')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:12<00:00,  4.13s/it]\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_____"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge features and Add target"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "target_train = spark.table('alfa.andrey_auto_target_train')\n",
        "target_train = target_train.withColumnRenamed('flag', 'target')\n",
        "target_train = target_train.select(['app_id', 'target'])\n",
        "target_train = target_train.join(train_smooth_table, on=['app_id'], how='left')"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "target_test = spark.table('alfa.andrey_auto_target_test')\n",
        "target_test = target_test.withColumn('target', sf.lit(-1))\n",
        "target_test = target_test.select(['app_id', 'target'])\n",
        "target_test = target_test.join(test_smooth_table, on=['app_id'], how='left')"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features after merge"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_train.columns), len(target_test.columns)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "(5, 5)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save tables"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "target_train.write.format('orc').mode('overwrite').saveAsTable('alfa.andrey_auto_payments_train_main__')\n",
        "spark.table('alfa.andrey_auto_payments_train_main__').toPandas().to_pickle('./train_smooth_.pkl')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.75 s, sys: 743 ms, total: 6.5 s\n",
            "Wall time: 4min 50s\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "target_test.write.format('orc').mode('overwrite').saveAsTable('alfa.andrey_auto_payments_test_main__')\n",
        "spark.table('alfa.andrey_auto_payments_test_main__').toPandas().to_pickle('./test_smooth_.pkl')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.06 s, sys: 322 ms, total: 3.38 s\n",
            "Wall time: 1min 18s\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "______"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.27.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}